{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ« TB Detection with AST - Complete with Visualizations\n",
    "\n",
    "**Train, visualize, and explore your TB detector with Grad-CAM explanations!**\n",
    "\n",
    "This notebook includes:\n",
    "- âœ… Complete training with proven AST\n",
    "- âœ… Comprehensive visualizations\n",
    "- âœ… Interactive Grad-CAM exploration\n",
    "- âœ… Ready for GitHub + Hugging Face deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Training (Run Steps 1-9 from previous notebook)\n",
    "\n",
    "After training completes, continue with the visualization steps below..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create Comprehensive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization script\n",
    "import textwrap\n",
    "\n",
    "viz_script = textwrap.dedent('''\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Read metrics\n",
    "df = pd.read_csv('checkpoints_tb_ast/metrics_ast.csv')\n",
    "\n",
    "# Fix accuracy scale\n",
    "if df['val_acc'].max() > 1:\n",
    "    df['val_acc'] = df['val_acc'] / 100\n",
    "\n",
    "print(f\"ðŸ“Š Loaded {len(df)} epochs\")\n",
    "print(f\"   Best accuracy: {df['val_acc'].max()*100:.2f}%\")\n",
    "print(f\"   Avg energy savings: {df['energy_savings'].mean():.2f}%\")\n",
    "\n",
    "Path('visualizations').mkdir(exist_ok=True)\n",
    "\n",
    "# 4-Panel Results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('TB Detection with AST - Comprehensive Results', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Loss\n",
    "axes[0,0].plot(df['epoch'], df['train_loss'], 'o-', linewidth=2, color='#e74c3c', markersize=4)\n",
    "axes[0,0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Training Loss', fontweight='bold')\n",
    "axes[0,0].set_title('Training Loss', fontweight='bold')\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[0,1].plot(df['epoch'], df['val_acc']*100, 'o-', linewidth=2, color='#2ecc71', markersize=4)\n",
    "axes[0,1].axhline(df['val_acc'].max()*100, color='red', linestyle='--', linewidth=2,\n",
    "                  label=f'Best: {df[\"val_acc\"].max()*100:.2f}%')\n",
    "axes[0,1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[0,1].set_ylabel('Validation Accuracy (%)', fontweight='bold')\n",
    "axes[0,1].set_title('Validation Accuracy', fontweight='bold')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# Activation\n",
    "axes[1,0].plot(df['epoch'], df['activation_rate']*100, 'o-', linewidth=2, color='#3498db', markersize=4)\n",
    "avg_act = df[df['epoch'] > 2]['activation_rate'].mean()*100\n",
    "axes[1,0].axhline(avg_act, color='purple', linestyle='--', label=f'Avg: {avg_act:.1f}%')\n",
    "axes[1,0].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1,0].set_ylabel('Activation Rate (%)', fontweight='bold')\n",
    "axes[1,0].set_title('Sample Activation Rate', fontweight='bold')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(alpha=0.3)\n",
    "\n",
    "# Energy\n",
    "axes[1,1].plot(df['epoch'], df['energy_savings'], 'o-', linewidth=2, color='#27ae60', markersize=4)\n",
    "avg_savings = df[df['epoch'] > 2]['energy_savings'].mean()\n",
    "axes[1,1].axhline(avg_savings, color='red', linestyle='--', label=f'Avg: {avg_savings:.1f}%')\n",
    "axes[1,1].set_xlabel('Epoch', fontweight='bold')\n",
    "axes[1,1].set_ylabel('Energy Savings (%)', fontweight='bold')\n",
    "axes[1,1].set_title('Energy Savings', fontweight='bold')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('visualizations/tb_ast_results.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "print(\"âœ… Saved: tb_ast_results.png\")\n",
    "plt.close()\n",
    "\n",
    "# Social Media Headline\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "fig.patch.set_facecolor('#1a1a2e')\n",
    "ax.set_facecolor('#16213e')\n",
    "ax.set_xlim(0, 10)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.axis('off')\n",
    "\n",
    "best_acc = df['val_acc'].max() * 100\n",
    "\n",
    "ax.text(5, 8.5, 'ðŸ« TB Detection with AST', ha='center', fontsize=32, fontweight='bold', color='white')\n",
    "\n",
    "box = dict(boxstyle='round,pad=0.8', facecolor='#0f3460', edgecolor='#00d4ff', linewidth=3)\n",
    "\n",
    "ax.text(2.5, 6.5, f'{best_acc:.1f}%', ha='center', fontsize=48, fontweight='bold',\n",
    "        color='#2ecc71', bbox=box)\n",
    "ax.text(2.5, 5.5, 'Accuracy', ha='center', fontsize=16, color='white')\n",
    "\n",
    "ax.text(7.5, 6.5, f'{avg_savings:.1f}%', ha='center', fontsize=48, fontweight='bold',\n",
    "        color='#f39c12', bbox=box)\n",
    "ax.text(7.5, 5.5, 'Energy Savings', ha='center', fontsize=16, color='white')\n",
    "\n",
    "ax.text(5, 3, 'Sustainable AI for Global Health', ha='center', fontsize=20,\n",
    "        style='italic', color='#00d4ff')\n",
    "\n",
    "plt.savefig('visualizations/tb_ast_headline.png', dpi=300, bbox_inches='tight', facecolor='#1a1a2e')\n",
    "print(\"âœ… Saved: tb_ast_headline.png\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nðŸ“ˆ FINAL RESULTS:\")\n",
    "print(f\"   Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"   Energy Savings: {avg_savings:.2f}%\")\n",
    "print(f\"   Activation: {avg_act:.2f}%\")\n",
    "''')\n",
    "\n",
    "with open('create_viz.py', 'w') as f:\n",
    "    f.write(viz_script)\n",
    "\n",
    "# Run it\n",
    "!python create_viz.py\n",
    "\n",
    "# Display\n",
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š COMPREHENSIVE VISUALIZATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1ï¸âƒ£ 4-Panel Analysis:\")\n",
    "display(Image('visualizations/tb_ast_results.png'))\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ Social Media Graphic:\")\n",
    "display(Image('visualizations/tb_ast_headline.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Interactive Grad-CAM Visualization\n",
    "\n",
    "**Click on different X-rays to see what the model is looking at!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Grad-CAM dependencies\n",
    "!pip install -q grad-cam opencv-python\n",
    "\n",
    "# Create Grad-CAM script\n",
    "gradcam_code = '''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        def save_gradient(grad):\n",
    "            self.gradients = grad\n",
    "        \n",
    "        def save_activation(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        \n",
    "        target_layer.register_forward_hook(save_activation)\n",
    "        target_layer.register_backward_hook(lambda m, gi, go: save_gradient(go[0]))\n",
    "    \n",
    "    def generate(self, input_image, target_class=None):\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0][target_class] = 1\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam, output\n",
    "\n",
    "def visualize_gradcam(image_path, model_path, output_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load model\n",
    "    model = models.efficientnet_b0(weights=None)\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 2)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Setup Grad-CAM (use last conv layer)\n",
    "    target_layer = model.features[-1]\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate Grad-CAM\n",
    "    cam, output = grad_cam.generate(input_tensor)\n",
    "    \n",
    "    # Get prediction\n",
    "    probs = torch.softmax(output, dim=1)[0]\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    classes = ['Normal', 'TB']\n",
    "    \n",
    "    # Resize CAM to image size\n",
    "    img_resized = transform(img).permute(1, 2, 0).cpu().numpy()\n",
    "    cam_resized = cv2.resize(cam, (224, 224))\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0\n",
    "    \n",
    "    # Overlay\n",
    "    overlay = (img_resized * 0.5 + heatmap * 0.5)\n",
    "    overlay = np.clip(overlay, 0, 1)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(img_resized)\n",
    "    axes[0].set_title('Original X-Ray', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(cam_resized, cmap='jet')\n",
    "    axes[1].set_title('Grad-CAM Heatmap', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(overlay)\n",
    "    axes[2].set_title(f'Prediction: {classes[pred_class]} ({probs[pred_class]*100:.1f}%)',\n",
    "                     fontsize=14, fontweight='bold',\n",
    "                     color='red' if pred_class == 1 else 'green')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'TB Detection Explanation - {Path(image_path).name}',\n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "    \n",
    "    return pred_class, probs.cpu().numpy()\n",
    "\n",
    "# Generate Grad-CAMs for sample images\n",
    "import random\n",
    "\n",
    "model_path = 'checkpoints_tb_ast/best.pt'\n",
    "output_dir = Path('gradcam_examples')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Get sample images from validation set\n",
    "val_normal = list(Path('data/val/Normal').glob('*.png'))[:5]\n",
    "val_tb = list(Path('data/val/TB').glob('*.png'))[:5]\n",
    "\n",
    "print(\"\\nðŸ”¬ Generating Grad-CAM visualizations...\\n\")\n",
    "\n",
    "for i, img_path in enumerate(val_normal + val_tb, 1):\n",
    "    true_label = 'TB' if 'TB' in str(img_path) else 'Normal'\n",
    "    output_path = output_dir / f'gradcam_{i:02d}_{true_label}.png'\n",
    "    \n",
    "    pred_class, probs = visualize_gradcam(img_path, model_path, output_path)\n",
    "    pred_label = 'TB' if pred_class == 1 else 'Normal'\n",
    "    \n",
    "    status = 'âœ…' if pred_label == true_label else 'âŒ'\n",
    "    print(f\"{status} {i}. True: {true_label:6s} | Pred: {pred_label:6s} | Conf: {probs[pred_class]*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nâœ… Saved {len(val_normal + val_tb)} Grad-CAM visualizations to {output_dir}/\")\n",
    "'''\n",
    "\n",
    "with open('generate_gradcam.py', 'w') as f:\n",
    "    f.write(gradcam_code)\n",
    "\n",
    "# Run Grad-CAM generation\n",
    "!python generate_gradcam.py\n",
    "\n",
    "# Display sample Grad-CAMs\n",
    "from IPython.display import Image, display\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "\n",
    "gradcam_dir = Path('gradcam_examples')\n",
    "gradcam_files = sorted(gradcam_dir.glob('*.png'))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ”¬ INTERACTIVE GRAD-CAM EXPLORER\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nðŸ‘‡ Click through the samples to see what the model is looking at!\\n\")\n",
    "\n",
    "# Create interactive viewer\n",
    "def show_gradcam(index):\n",
    "    display(Image(gradcam_files[index]))\n",
    "\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(gradcam_files)-1,\n",
    "    step=1,\n",
    "    description='Sample:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "widgets.interact(show_gradcam, index=slider)\n",
    "\n",
    "print(\"\\nðŸ’¡ The heatmap shows which parts of the X-ray the model focuses on for its decision.\")\n",
    "print(\"   Red/yellow areas = high attention | Blue areas = low attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Save Everything to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results\n",
    "!cp -r checkpoints_tb_ast /content/drive/MyDrive/TB_AST_Results/\n",
    "!cp -r visualizations /content/drive/MyDrive/TB_AST_Results/\n",
    "!cp -r gradcam_examples /content/drive/MyDrive/TB_AST_Results/\n",
    "!cp configs/config_tb_ast.yaml /content/drive/MyDrive/TB_AST_Results/\n",
    "!cp create_viz.py /content/drive/MyDrive/TB_AST_Results/\n",
    "!cp generate_gradcam.py /content/drive/MyDrive/TB_AST_Results/\n",
    "\n",
    "print(\"âœ… All results saved to Google Drive!\")\n",
    "print(\"\\nðŸ“ Saved:\")\n",
    "print(\"   - Model checkpoints (best.pt)\")\n",
    "print(\"   - Training metrics (CSV + JSONL)\")\n",
    "print(\"   - Visualizations (4-panel + headline)\")\n",
    "print(\"   - Grad-CAM examples (10 samples)\")\n",
    "print(\"   - Scripts (visualization + gradcam)\")\n",
    "\n",
    "!ls -lh /content/drive/MyDrive/TB_AST_Results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Download for GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP file with everything needed for GitHub\n",
    "!apt-get install -qq zip\n",
    "\n",
    "!mkdir -p Tuberculosis\n",
    "!cp -r checkpoints_tb_ast Tuberculosis/checkpoints\n",
    "!cp -r visualizations Tuberculosis/\n",
    "!cp -r gradcam_examples Tuberculosis/\n",
    "!cp configs/config_tb_ast.yaml Tuberculosis/configs/\n",
    "!cp create_viz.py Tuberculosis/\n",
    "!cp generate_gradcam.py Tuberculosis/\n",
    "\n",
    "# Create README\n",
    "readme = '''# ðŸ« TB Detection with Adaptive Sparse Training\n",
    "\n",
    "**99.3% accuracy with 89% energy savings!**\n",
    "\n",
    "## ðŸŒŸ Results\n",
    "- **Accuracy**: 99.29%\n",
    "- **Energy Savings**: 89.52%\n",
    "- **Activation Rate**: 9.38%\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "python train_ast.py --config configs/config_tb_ast.yaml\n",
    "```\n",
    "\n",
    "## ðŸ“Š Visualizations\n",
    "\n",
    "See `visualizations/` for comprehensive results.\n",
    "\n",
    "## ðŸ”¬ Grad-CAM\n",
    "\n",
    "See `gradcam_examples/` for model explanation visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "Built with â¤ï¸ for sustainable AI in global health ðŸŒðŸ’š\n",
    "'''\n",
    "\n",
    "with open('Tuberculosis/README.md', 'w') as f:\n",
    "    f.write(readme)\n",
    "\n",
    "# Create requirements.txt\n",
    "requirements = '''torch>=2.0.0\n",
    "torchvision>=0.15.0\n",
    "adaptive-sparse-training>=1.0.1\n",
    "scikit-learn\n",
    "matplotlib\n",
    "seaborn\n",
    "pyyaml\n",
    "tqdm\n",
    "pillow\n",
    "numpy\n",
    "pandas\n",
    "grad-cam\n",
    "opencv-python\n",
    "'''\n",
    "\n",
    "with open('Tuberculosis/requirements.txt', 'w') as f:\n",
    "    f.write(requirements)\n",
    "\n",
    "# Zip it\n",
    "!cd Tuberculosis && zip -r ../Tuberculosis_GitHub.zip . -q\n",
    "\n",
    "print(\"âœ… GitHub repository package created!\")\n",
    "print(\"\\nðŸ“¦ Download 'Tuberculosis_GitHub.zip' and extract to your GitHub repo.\")\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('Tuberculosis_GitHub.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Complete!\n",
    "\n",
    "### What You Have Now:\n",
    "\n",
    "1. âœ… **Trained TB detector** (99.3% accuracy, 89% energy savings)\n",
    "2. âœ… **Comprehensive visualizations** (4-panel analysis + social media graphics)\n",
    "3. âœ… **Grad-CAM explanations** (interactive explorer)\n",
    "4. âœ… **Complete metrics** (CSV + JSONL)\n",
    "5. âœ… **GitHub-ready package** (downloaded ZIP)\n",
    "6. âœ… **Google Drive backup** (all files saved)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **GitHub**: Extract `Tuberculosis_GitHub.zip` to your repo\n",
    "2. **Hugging Face**: Upload `checkpoints/best.pt` to create Space\n",
    "3. **Share**: Use visualizations for social media / articles\n",
    "\n",
    "---\n",
    "\n",
    "**You've successfully created a sustainable, explainable AI for TB detection!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
