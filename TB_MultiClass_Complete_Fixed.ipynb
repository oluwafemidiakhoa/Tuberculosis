{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Multi-Class Chest X-Ray Disease Detection\n",
    "\n",
    "**Production Notebook**: 4-Class Classification (Normal | TB | Pneumonia | COVID-19)\n",
    "\n",
    "- **Model**: EfficientNet-B2 + Adaptive Sparse Training (AST)\n",
    "- **Target**: 92-95% accuracy, 85-90% energy savings\n",
    "- **Features**: Grad-CAM explainability, advanced augmentation, class-weighted loss\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision kaggle matplotlib seaborn pillow opencv-python scikit-learn pandas tqdm\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment and setup\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "    print(\"Environment: Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Environment: Local Jupyter\")\n",
    "\n",
    "# Clone repository if needed\n",
    "if not os.path.exists('train_multiclass_simple.py'):\n",
    "    !git clone https://github.com/oluwafemidiakhoa/Tuberculosis.git\n",
    "    %cd Tuberculosis\n",
    "else:\n",
    "    print(\"Already in Tuberculosis directory\")\n",
    "\n",
    "# Setup Kaggle credentials\n",
    "kaggle_dir = Path.home() / '.kaggle'\n",
    "kaggle_file = kaggle_dir / 'kaggle.json'\n",
    "\n",
    "if not kaggle_file.exists():\n",
    "    if IN_COLAB:\n",
    "        print(\"Upload kaggle.json:\")\n",
    "        uploaded = files.upload()\n",
    "        kaggle_dir.mkdir(parents=True, exist_ok=True)\n",
    "        !cp kaggle.json ~/.kaggle/\n",
    "        !chmod 600 ~/.kaggle/kaggle.json\n",
    "    else:\n",
    "        print(\"Place kaggle.json in ~/.kaggle/\")\n",
    "        print(\"Download from: https://www.kaggle.com/settings/account\")\n",
    "else:\n",
    "    !chmod 600 ~/.kaggle/kaggle.json\n",
    "    print(\"✓ Kaggle configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "datasets = [\n",
    "    ('tawsifurrahman/covid19-radiography-database', 'data_covid', 'COVID-19 & Normal'),\n",
    "    ('paultimothymooney/chest-xray-pneumonia', 'data_pneumonia', 'Pneumonia'),\n",
    "    ('tawsifurrahman/tuberculosis-tb-chest-xray-dataset', 'data_tb', 'TB')\n",
    "]\n",
    "\n",
    "for dataset_id, output_dir, name in datasets:\n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"Downloading {name}...\")\n",
    "        !kaggle datasets download -d {dataset_id}\n",
    "        zip_name = dataset_id.split('/')[-1] + '.zip'\n",
    "        !unzip -q {zip_name} -d {output_dir}\n",
    "        !rm {zip_name}\n",
    "        print(f\"✓ {name} ready\")\n",
    "    else:\n",
    "        print(f\"✓ {name} exists\")\n",
    "\n",
    "print(\"\\n✓ All datasets downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize dataset\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "data_dir = Path('data_multiclass')\n",
    "\n",
    "if (data_dir / 'train' / 'Normal').exists() and len(list((data_dir / 'train' / 'Normal').glob('*.png'))) > 100:\n",
    "    print(\"✓ Dataset already organized\")\n",
    "else:\n",
    "    print(\"Organizing dataset...\\n\")\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for cls in ['Normal', 'TB', 'Pneumonia', 'COVID']:\n",
    "            (data_dir / split / cls).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def is_valid_image(img_path):\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                img.verify()\n",
    "            with Image.open(img_path) as img:\n",
    "                img.load()\n",
    "                if img.size[0] < 10 or img.size[1] < 10:\n",
    "                    return False\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def copy_images(source_patterns, class_name, target_root, max_count=3000):\n",
    "        images = []\n",
    "        corrupted = 0\n",
    "        \n",
    "        for pattern in source_patterns:\n",
    "            for img_path in Path('.').rglob(pattern):\n",
    "                if is_valid_image(img_path):\n",
    "                    images.append(img_path)\n",
    "                else:\n",
    "                    corrupted += 1\n",
    "        \n",
    "        print(f\"  {class_name}: {len(images)} valid ({corrupted} corrupted)\")\n",
    "        \n",
    "        random.shuffle(images)\n",
    "        images = images[:max_count]\n",
    "        \n",
    "        n = len(images)\n",
    "        n_train = int(0.70 * n)\n",
    "        n_val = int(0.15 * n)\n",
    "        \n",
    "        splits = {\n",
    "            'train': images[:n_train],\n",
    "            'val': images[n_train:n_train+n_val],\n",
    "            'test': images[n_train+n_val:]\n",
    "        }\n",
    "        \n",
    "        for split_name, split_images in splits.items():\n",
    "            for i, img_path in enumerate(split_images):\n",
    "                dest = target_root / split_name / class_name / f\"{class_name}_{i}.png\"\n",
    "                try:\n",
    "                    shutil.copy(img_path, dest)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return len(splits['train']), len(splits['val']), len(splits['test'])\n",
    "    \n",
    "    for patterns, cls_name in [\n",
    "        (['data_covid/**/Normal/**/*.png', 'data_covid/**/Normal/**/*.jpg'], 'Normal'),\n",
    "        (['data_covid/**/COVID/**/*.png', 'data_covid/**/COVID/**/*.jpg'], 'COVID'),\n",
    "        (['data_pneumonia/**/PNEUMONIA/**/*.jpeg', 'data_pneumonia/**/PNEUMONIA/**/*.png'], 'Pneumonia'),\n",
    "        (['data_tb/**/Tuberculosis/**/*.png', 'data_tb/**/Tuberculosis/**/*.jpg'], 'TB')\n",
    "    ]:\n",
    "        train, val, test = copy_images(patterns, cls_name, data_dir, 3000)\n",
    "        print(f\"    Train: {train}, Val: {val}, Test: {test}\\n\")\n",
    "    \n",
    "    print(\"✓ Dataset organized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "CLASSES = ['Normal', 'TB', 'Pneumonia', 'COVID']\n",
    "\n",
    "train_counts = [len(list((data_dir / 'train' / cls).glob('*.png'))) for cls in CLASSES]\n",
    "val_counts = [len(list((data_dir / 'val' / cls).glob('*.png'))) for cls in CLASSES]\n",
    "test_counts = [len(list((data_dir / 'test' / cls).glob('*.png'))) for cls in CLASSES]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Dataset Distribution', fontsize=20, fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
    "axes[0].pie(train_counts, labels=CLASSES, autopct='%1.1f%%',\n",
    "           colors=colors, explode=[0.05]*4, shadow=True, startangle=90,\n",
    "           textprops={'fontsize': 14, 'weight': 'bold'})\n",
    "axes[0].set_title('Class Distribution', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "x = np.arange(len(CLASSES))\n",
    "width = 0.25\n",
    "axes[1].bar(x - width, train_counts, width, label='Train (70%)', color='#3498db')\n",
    "axes[1].bar(x, val_counts, width, label='Val (15%)', color='#e67e22')\n",
    "axes[1].bar(x + width, test_counts, width, label='Test (15%)', color='#95a5a6')\n",
    "axes[1].set_ylabel('Number of Images', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Train/Val/Test Split', fontsize=16, fontweight='bold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(CLASSES)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dataset_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDataset Summary:\")\n",
    "for i, cls in enumerate(CLASSES):\n",
    "    total = train_counts[i] + val_counts[i] + test_counts[i]\n",
    "    print(f\"  {cls:12s}: {total:4d} images (Train: {train_counts[i]}, Val: {val_counts[i]}, Test: {test_counts[i]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Model Training\n",
    "\n",
    "**Config**: EfficientNet-B2 | 100 epochs | Batch 32 | AST 15% activation  \n",
    "**Expected**: 92-95% accuracy, 85-90% energy savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "!python train_optimized_90_95.py\n",
    "\n",
    "print(\"\\n✓ Training complete\")\n",
    "print(\"  Checkpoints: checkpoints_multiclass_optimized/\")\n",
    "print(\"  Metrics: checkpoints_multiclass_optimized/metrics_optimized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training metrics\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('checkpoints_multiclass_optimized/metrics_optimized.csv')\n",
    "\n",
    "if df['val_acc'].max() > 1:\n",
    "    df['val_acc'] = df['val_acc'] / 100\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('Training Results - Multi-Class Disease Detection', fontsize=24, fontweight='bold')\n",
    "\n",
    "# Loss\n",
    "axes[0,0].plot(df['epoch'], df['train_loss'], label='Train', linewidth=3, color='#e74c3c')\n",
    "axes[0,0].plot(df['epoch'], df['val_loss'], label='Validation', linewidth=3, color='#3498db')\n",
    "axes[0,0].set_xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Loss', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_title('Training & Validation Loss', fontsize=16, fontweight='bold')\n",
    "axes[0,0].legend(fontsize=12)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "best_acc = df['val_acc'].max() * 100\n",
    "axes[0,1].plot(df['epoch'], df['val_acc']*100, linewidth=3, color='#2ecc71')\n",
    "axes[0,1].axhline(best_acc, color='#e74c3c', linestyle='--', linewidth=2.5, \n",
    "                 label=f'Best: {best_acc:.2f}%')\n",
    "axes[0,1].axhline(90, color='#f39c12', linestyle=':', linewidth=2, label='Target: 90%')\n",
    "axes[0,1].set_xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_title(f'Validation Accuracy (Best: {best_acc:.2f}%)', fontsize=16, fontweight='bold')\n",
    "axes[0,1].legend(fontsize=12)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "axes[0,1].set_ylim([0, 105])\n",
    "\n",
    "# Activation rate\n",
    "avg_activation = df['activation_rate'].mean() * 100\n",
    "axes[1,0].plot(df['epoch'], df['activation_rate']*100, linewidth=3, color='#f39c12')\n",
    "axes[1,0].axhline(15, color='#e74c3c', linestyle='--', linewidth=2.5, label='Target: 15%')\n",
    "axes[1,0].set_xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_ylabel('Activation Rate (%)', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_title(f'Network Activation (Avg: {avg_activation:.2f}%)', fontsize=16, fontweight='bold')\n",
    "axes[1,0].legend(fontsize=12)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Energy savings\n",
    "avg_energy = df['energy_savings'].mean()\n",
    "axes[1,1].plot(df['epoch'], df['energy_savings'], linewidth=3, color='#9b59b6')\n",
    "axes[1,1].fill_between(df['epoch'], df['energy_savings'], alpha=0.3, color='#9b59b6')\n",
    "axes[1,1].set_xlabel('Epoch', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_ylabel('Energy Savings (%)', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_title(f'Energy Efficiency (Avg: {avg_energy:.2f}%)', fontsize=16, fontweight='bold')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].set_ylim([0, 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"  Best Accuracy: {best_acc:.2f}%\")\n",
    "print(f\"  Avg Energy Savings: {avg_energy:.2f}%\")\n",
    "print(f\"  Avg Activation Rate: {avg_activation:.2f}%\")\n",
    "\n",
    "if 'Normal_acc' in df.columns:\n",
    "    best_epoch = df['val_acc'].idxmax()\n",
    "    print(f\"\\nPer-Class Accuracy (Epoch {df.iloc[best_epoch]['epoch']:.0f}):\")\n",
    "    for cls in CLASSES:\n",
    "        if f'{cls}_acc' in df.columns:\n",
    "            acc = df.iloc[best_epoch][f'{cls}_acc']\n",
    "            print(f\"  {cls:12s}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = models.efficientnet_b2(weights=None)\n",
    "model.classifier[1] = nn.Linear(1408, 4)\n",
    "\n",
    "checkpoint_path = 'checkpoints_multiclass_optimized/best.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "# Extract state dict\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    print(f\"Checkpoint - Epoch: {checkpoint.get('epoch', 'N/A')}, Acc: {checkpoint.get('val_acc', 0):.2f}%\")\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "\n",
    "# Clean state dict\n",
    "clean_state_dict = OrderedDict()\n",
    "for key, value in state_dict.items():\n",
    "    if key.startswith('model.'):\n",
    "        clean_state_dict[key[6:]] = value\n",
    "    elif key != 'activation_mask':\n",
    "        clean_state_dict[key] = value\n",
    "\n",
    "model.load_state_dict(clean_state_dict, strict=False)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"✓ Model loaded\")\n",
    "\n",
    "# Transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def predict(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "        probs = torch.softmax(out, dim=1)[0]\n",
    "    pred_idx = out.argmax(dim=1).item()\n",
    "    return CLASSES[pred_idx], float(probs[pred_idx]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "print(\"Evaluating test set...\")\n",
    "for class_idx, cls in enumerate(CLASSES):\n",
    "    test_path = data_dir / 'test' / cls\n",
    "    test_imgs = list(test_path.glob('*.png'))[:100]\n",
    "    \n",
    "    for img_path in test_imgs:\n",
    "        try:\n",
    "            pred, _ = predict(img_path)\n",
    "            all_preds.append(CLASSES.index(pred))\n",
    "            all_labels.append(class_idx)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "if all_preds:\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=CLASSES, digits=3))\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "               cbar_kws={'label': 'Count'},\n",
    "               annot_kws={'fontsize': 14, 'fontweight': 'bold'})\n",
    "    ax.set_title('Confusion Matrix', fontsize=18, fontweight='bold', pad=20)\n",
    "    ax.set_ylabel('True Label', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\n✓ Confusion matrix saved\")\n",
    "else:\n",
    "    print(\"No predictions - check test images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization\n",
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        def save_gradient(grad):\n",
    "            self.gradients = grad\n",
    "        \n",
    "        def save_activation(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "        \n",
    "        target_layer.register_forward_hook(save_activation)\n",
    "        target_layer.register_full_backward_hook(\n",
    "            lambda m, gi, go: save_gradient(go[0])\n",
    "        )\n",
    "    \n",
    "    def generate(self, input_img):\n",
    "        output = self.model(input_img)\n",
    "        pred_class = output.argmax(dim=1)\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0][pred_class] = 1\n",
    "        output.backward(gradient=one_hot, retain_graph=True)\n",
    "        \n",
    "        if self.gradients is None:\n",
    "            return None, output\n",
    "        \n",
    "        weights = self.gradients.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * self.activations).sum(dim=1, keepdim=True)\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam.squeeze().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        \n",
    "        return cam, output\n",
    "\n",
    "grad_cam = GradCAM(model, model.features[-1])\n",
    "\n",
    "# Generate for each class\n",
    "samples = []\n",
    "for cls in CLASSES:\n",
    "    test_path = data_dir / 'test' / cls\n",
    "    img_files = list(test_path.glob('*.png'))\n",
    "    if img_files:\n",
    "        samples.append((img_files[0], cls))\n",
    "\n",
    "if samples:\n",
    "    fig, axes = plt.subplots(len(samples), 3, figsize=(15, 4.5*len(samples)))\n",
    "    if len(samples) == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    fig.suptitle('Grad-CAM Explainable AI', fontsize=20, fontweight='bold')\n",
    "    \n",
    "    for idx, (img_path, true_class) in enumerate(samples):\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.set_grad_enabled(True):\n",
    "            cam, output = grad_cam.generate(img_tensor)\n",
    "        \n",
    "        probs = torch.softmax(output, dim=1)[0].cpu().detach().numpy()\n",
    "        pred_idx = output.argmax(dim=1).item()\n",
    "        pred_class = CLASSES[pred_idx]\n",
    "        confidence = probs[pred_idx] * 100\n",
    "        \n",
    "        img_resized = img.resize((224, 224))\n",
    "        img_array = np.array(img_resized)\n",
    "        \n",
    "        if cam is not None:\n",
    "            cam_resized = cv2.resize(cam, (224, 224))\n",
    "            heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "            heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "            overlay = img_array * 0.5 + heatmap * 0.5\n",
    "            overlay = np.clip(overlay, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            heatmap = np.zeros_like(img_array)\n",
    "            overlay = img_array\n",
    "        \n",
    "        axes[idx, 0].imshow(img_resized)\n",
    "        axes[idx, 0].set_title(f'Original\\n{true_class}', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(heatmap)\n",
    "        axes[idx, 1].set_title('Attention Map', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        status = '✓' if pred_class == true_class else '✗'\n",
    "        color = 'green' if pred_class == true_class else 'red'\n",
    "        axes[idx, 2].imshow(overlay)\n",
    "        axes[idx, 2].set_title(f'{status} {pred_class} ({confidence:.1f}%)',\n",
    "                              fontsize=12, fontweight='bold', color=color)\n",
    "        axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gradcam_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"✓ Grad-CAM saved\")\n",
    "else:\n",
    "    print(\"No test images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 5. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and download results\n",
    "results = [\n",
    "    'checkpoints_multiclass_optimized/best.pt',\n",
    "    'checkpoints_multiclass_optimized/metrics_optimized.csv',\n",
    "    'dataset_distribution.png',\n",
    "    'training_results.png',\n",
    "    'confusion_matrix.png',\n",
    "    'gradcam_visualization.png'\n",
    "]\n",
    "\n",
    "print(\"Generated Files:\\n\")\n",
    "for file in results:\n",
    "    if os.path.exists(file):\n",
    "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
    "        print(f\"  ✓ {file} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ✗ {file}\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\nDownloading...\")\n",
    "    for file in results:\n",
    "        if os.path.exists(file):\n",
    "            try:\n",
    "                files.download(file)\n",
    "            except:\n",
    "                pass\n",
    "    print(\"✓ Complete\")\n",
    "else:\n",
    "    print(\"\\n✓ Files saved locally\")\n",
    "\n",
    "print(\"\\nDeployment: Use gradio_app/app.py with best.pt\")\n",
    "print(\"Repository: https://github.com/oluwafemidiakhoa/Tuberculosis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
